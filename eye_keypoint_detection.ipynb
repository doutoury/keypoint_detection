{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd08182dd0ad4173cdddc5298b982923877be00ee4d2f569af5d6459bf4e939e93c",
   "display_name": "Python 3.7.10 64-bit ('aiffel': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "8182dd0ad4173cdddc5298b982923877be00ee4d2f569af5d6459bf4e939e93c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<br>\n",
    "\n",
    "# Eye Keypoint Detector\n",
    "---\n",
    "<br>\n",
    "\n",
    "## 딥러닝 모델을 이용한 키포인트 검출 <br><br>\n",
    "\n",
    "기존 키포인트 검출 모델보다 더 좋은 성능을 만들기 위해 <br>\n",
    "딥러닝 모델을 이용한 키포인트 검출을 시도\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "## 데이터 준비 <br><br>\n",
    "\n",
    "\n",
    "학습에 필요한 데이터셋이 충분히 많으면 상관 없지만, <br>\n",
    "데이터셋이 부족할 경우 직접 데이터셋을 생성해야할 때도 있습니다. <br><br>\n",
    "\n",
    "이 때, 수 많은 데이터셋을 자동으로 생성하기 위해 <br>\n",
    "필요한 데이터셋에 따라 여러가지 방법이 사용됩니다. <br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "### Data Annotation <br><br>\n",
    "\n",
    "\n",
    "눈동자 검출 모델을 생성하기 위해서 대량의 '눈동자 위치 라벨' 이 필요 <br>\n",
    "( 성능 확인을 위해서는 10000 개 이상 필요 ) <br><br>\n",
    "\n",
    "LFW 데이터셋에 눈동자 라벨링을 위한 어노테이션 함수를 적용하여 <br>\n",
    "필요한 데이터셋을 대량으로 생성해 봅시다. <br>\n",
    "( 여기서는 ```prepare_eye_dataset.py``` 를 실행하여 어노테이션된 데이터셋 생성 )\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 임포트\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "TensorFlow Hub에서 제공하는 pretrained image feature embedding 을 이용하여 fine tuning <br><br>\n",
    "\n",
    "데이터를 케라스 ImageDataGenerator 형식으로 읽기 <br>\n",
    "( 여기서는 라벨이 image 형태로 저장되 있습니다 )\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23680 23680\n",
      "Found 23680 images belonging to 1 classes.\n",
      "Found 23680 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# 어노테이션된 (이미지)데이터를 불러와 학습을 위한 데이터 준비\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "home_dir = os.getenv('HOME')+'/lfw'\n",
    "list_image = sorted(glob.glob(home_dir+'/data/train/input/img/*.png'))\n",
    "list_label = sorted(glob.glob(home_dir+'/data/train/label/mask/*.png'))\n",
    "print (len(list_image), len(list_label))\n",
    "\n",
    "# 32의 배수를 벗어나는 파일 경로들을 담은 list\n",
    "list_image_out_of_range = list_image[len(list_image) - (len(list_image) % 32):]\n",
    "list_label_out_of_range = list_label[len(list_label) - (len(list_label) % 32):]\n",
    "\n",
    "# 해당 list가 존재한다면, 파일 삭제\n",
    "if list_image_out_of_range:\n",
    "    for path in list_image_out_of_range:\n",
    "        os.remove(path)\n",
    "if list_label_out_of_range:\n",
    "    for path in list_label_out_of_range:\n",
    "        os.remove(path)\n",
    "\n",
    "IMAGE_SHAPE = (80, 120)\n",
    "data_root = home_dir+'/data/train/input'\n",
    "label_root = home_dir+'/data/train/label'\n",
    "\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "label_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "image_data = image_generator.flow_from_directory(str(data_root), class_mode=None, target_size=IMAGE_SHAPE, batch_size=32)\n",
    "label_data = label_generator.flow_from_directory(str(label_root), class_mode=None, target_size=IMAGE_SHAPE, batch_size=32)"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### Dataset generator <br><br>\n",
    "\n",
    "모델 학습을 위한 데이터셋을 생성하는 함수를 작성 <br><br>\n",
    "\n",
    "image_generator 와 label generator 를 학습할 수 있는 입출력 형식으로 편집 <br>\n",
    "텐서플로우의 제너레이터(generator) 형식을 사용하고 있기 때문에 출력 형식도 맞추어 주기 <br><br>\n",
    "\n",
    "참고. <br>\n",
    "[제네레이터](https://tensorflow.blog/%ED%9A%8C%EC%98%A4%EB%A6%AC%EB%B0%94%EB%9E%8C%EC%9D%84-%ED%83%84-%ED%8C%8C%EC%9D%B4%EC%8D%AC/%EC%A0%9C%EB%84%88%EB%A0%88%EC%9D%B4%ED%84%B0/)\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습을 위한 데이터셋 생성하는 함수 작성\n",
    "\n",
    "def user_generation(train_generator, label_generator):\n",
    "    h, w = train_generator.target_size\n",
    "    for images, labels in zip(train_generator, label_generator):\n",
    "        images /= 255.\n",
    "        images = images[..., ::-1] # rgb to bgr\n",
    "\n",
    "        list_point_labels = []\n",
    "        for img, label in zip(images, labels):\n",
    "\n",
    "            eye_ls = np.where(label==1) # leftside\n",
    "            eye_rs = np.where(label==2) # rightside\n",
    "            eye_center = np.where(label==3)\n",
    "\n",
    "            lx, ly = [eye_ls[1].mean(), eye_ls[0].mean()]\n",
    "            rx, ry = [eye_rs[1].mean(), eye_rs[0].mean()]\n",
    "            cx, cy = [eye_center[1].mean(), eye_center[0].mean()]\n",
    "\n",
    "            if len(eye_ls[0])==0 or len(eye_ls[1])==0:\n",
    "                lx, ly = [0, 0]\n",
    "            if len(eye_rs[0])==0 or len(eye_rs[1])==0:\n",
    "                rx, ry = [w, h]\n",
    "            if len(eye_center[0])==0 or len(eye_center[1])==0:\n",
    "                cx, cy = [0, 0]\n",
    "\n",
    "            np_point_label = np.array([lx/w,ly/h,rx/w,ry/h,cx/w,cy/h], dtype=np.float32)\n",
    "\n",
    "            list_point_labels.append(np_point_label)\n",
    "        np_point_labels = np.array(list_point_labels)\n",
    "        yield (images, np_point_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(80, 120, 3) [0.        0.        1.        1.        0.5805595 0.4375   ]\n",
      "(80, 120, 3) [0.         0.         1.         1.         0.39166668 0.18701509]\n",
      "/home/ssac29/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: Mean of empty slice.\n",
      "  app.launch_new_instance()\n",
      "/home/ssac29/anaconda3/envs/aiffel/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/ssac29/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: Mean of empty slice.\n"
     ]
    }
   ],
   "source": [
    "# 생성한 user_generation 제네레이터 함수로 데이터 포인트를 뽑아 확인\n",
    "# 120x80의 정해진 크기로 이미지가 잘 출력되고 라벨 또한 0~1 갑ㅅ으로 정규화(normalize) 되어 있는 것을 확인\n",
    "\n",
    "user_train_generator = user_generation(image_data, label_data)\n",
    "for i in range(2):\n",
    "    dd = next(user_train_generator)\n",
    "    print (dd[0][0].shape, dd[1][0])"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "## 모델 설계 : Keypoint 검출 딥러닝 모델 만들기 <br><br>\n",
    "\n",
    "\n",
    "데이터가 부족하므로 '미리 학습된 모델' 을 적극 활용 <br>\n",
    "\n",
    "- TensorFlow Hub 에서 ResNet 의 feature Extraction (특성추출) 부분을 백본(backbone) 모델로 사용 <br>\n",
    "\n",
    "- ```tf.keras.Sequential()``` 을 이용해 <br>\n",
    "backbone 네트워크 + fully connected layer 의 형태로 레이어를 추가로 쌓아 쉽게 모델을 완성 <br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "- 데이터 제네레이터에서 출력을 (x,y)좌표 2개 * 점 3개 인 6개로 정했기 때문에, <br>\n",
    "```num_classes = 6``` 으로 설정 <br><br>\n",
    "\n",
    "- 이 문제는 점을 맞는 위치로 추정하는 position regression 문제이기 때문에 <br>\n",
    "loss와 metric을 각각 mse 와 mae 로 설정 <br>\n",
    "( mae 를 통해서 픽셀 위치가 평균적으로 얼마나 차이나는지 확인하면서 학습할 수 있습니다 )\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(32, 2048)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f2100f98dd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f2100f98dd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f2100f98dd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 2048)              23564800  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 12294     \n",
      "=================================================================\n",
      "Total params: 23,577,094\n",
      "Trainable params: 12,294\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성 후 확인\n",
    "\n",
    "''' tf hub feature_extractor '''\n",
    "feature_extractor_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
    "                                            input_shape=(80,120,3))\n",
    "\n",
    "image_batch = next(image_data)\n",
    "feature_batch = feature_extractor_layer(image_batch)\n",
    "print(feature_batch.shape)\n",
    "\n",
    "num_classes = 6\n",
    "\n",
    "feature_extractor_layer.trainable = False\n",
    "model = tf.keras.Sequential([\n",
    "    feature_extractor_layer,\n",
    "    #layers.Dense(1024, activation='relu'),\n",
    "    #layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  loss='mse',\n",
    "  metrics=['mae']\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate 조절하는 함수 작성 (지수적으로 감소하도록)\n",
    "\n",
    "def lr_step_decay(epoch):\n",
    "      init_lr = 0.0005 #self.flag.initial_learning_rate\n",
    "      lr_decay = 0.5 #self.flag.learning_rate_decay_factor\n",
    "      epoch_per_decay = 2 #self.flag.epoch_per_decay\n",
    "      lrate = init_lr * math.pow(lr_decay, math.floor((1+epoch)/epoch_per_decay))\n",
    "      return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "\n",
    "steps_per_epoch = image_data.samples//image_data.batch_size\n",
    "print (image_data.samples, image_data.batch_size, steps_per_epoch)\n",
    "# 23712 32 741 -> 데이터를 batch_size(32) 의 배수로 맞춰 준비해 주세요. \n",
    "\n",
    "assert(image_data.samples % image_data.batch_size == 0)  # 데이터가 32의 배수가 되지 않으면 model.fit()에서 에러가 발생합니다.\n",
    "\n",
    "learning_rate = LearningRateScheduler(lr_step_decay)\n",
    "\n",
    "history = model.fit(user_train_generator, epochs=10,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    callbacks = [learning_rate]\n",
    "                    )"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "## 모델 학습 결과 평가 <br><br>\n",
    "\n",
    "검증(validation)용 데이터는 섞어줄(shuffle) 필요가 없기 때문에 <br>\n",
    "```shuffle=False``` 옵션을 추가\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "IMAGE_SHAPE = (80, 120)\n",
    "\n",
    "home_dir = os.getenv('HOME')+'/lfw'\n",
    "\n",
    "val_data_root = home_dir + '/data/val/input'\n",
    "val_label_root = home_dir + '/data/val/label'\n",
    "\n",
    "image_generator_val = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "label_generator_val = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "image_data_val = image_generator.flow_from_directory(str(val_data_root), class_mode=None, target_size=IMAGE_SHAPE, shuffle=False)\n",
    "label_data_val = label_generator.flow_from_directory(str(val_label_root), class_mode=None, target_size=IMAGE_SHAPE, shuffle=False)"
   ]
  }
 ]
}