{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd08182dd0ad4173cdddc5298b982923877be00ee4d2f569af5d6459bf4e939e93c",
   "display_name": "Python 3.7.10 64-bit ('aiffel': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "8182dd0ad4173cdddc5298b982923877be00ee4d2f569af5d6459bf4e939e93c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<br>\n",
    "\n",
    "# Eye Keypoint Detector\n",
    "---\n",
    "<br>\n",
    "\n",
    "## 딥러닝 모델을 이용한 키포인트 검출 <br><br>\n",
    "\n",
    "기존 키포인트 검출 모델보다 더 좋은 성능을 만들기 위해 <br>\n",
    "딥러닝 모델을 이용한 키포인트 검출을 시도\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "## 데이터 준비 <br><br>\n",
    "\n",
    "\n",
    "학습에 필요한 데이터셋이 충분히 많으면 상관 없지만, <br>\n",
    "데이터셋이 부족할 경우 직접 데이터셋을 생성해야할 때도 있습니다. <br><br>\n",
    "\n",
    "이 때, 수 많은 데이터셋을 자동으로 생성하기 위해 <br>\n",
    "필요한 데이터셋에 따라 여러가지 방법이 사용됩니다. <br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "### Data Annotation <br><br>\n",
    "\n",
    "\n",
    "눈동자 검출 모델을 생성하기 위해서 대량의 '눈동자 위치 라벨' 이 필요 <br>\n",
    "( 성능 확인을 위해서는 10000 개 이상 필요 ) <br><br>\n",
    "\n",
    "LFW 데이터셋에 눈동자 라벨링을 위한 어노테이션 함수를 적용하여 <br>\n",
    "필요한 데이터셋을 대량으로 생성해 봅시다. <br>\n",
    "( 여기서는 ```prepare_eye_dataset.py``` 를 실행하여 어노테이션된 데이터셋 생성 )\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 임포트\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "TensorFlow Hub에서 제공하는 pretrained image feature embedding 을 이용하여 fine tuning <br><br>\n",
    "\n",
    "데이터를 케라스 ImageDataGenerator 형식으로 읽기 <br>\n",
    "( 여기서는 라벨이 image 형태로 저장되 있습니다 )\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23680 23680\n",
      "Found 23680 images belonging to 1 classes.\n",
      "Found 23680 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# 어노테이션된 (이미지)데이터를 불러와 학습을 위한 데이터 준비\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "home_dir = os.getenv('HOME')+'/lfw'\n",
    "list_image = sorted(glob.glob(home_dir+'/data/train/input/img/*.png'))\n",
    "list_label = sorted(glob.glob(home_dir+'/data/train/label/mask/*.png'))\n",
    "print (len(list_image), len(list_label))\n",
    "\n",
    "# 32의 배수를 벗어나는 파일 경로들을 담은 list\n",
    "list_image_out_of_range = list_image[len(list_image) - (len(list_image) % 32):]\n",
    "list_label_out_of_range = list_label[len(list_label) - (len(list_label) % 32):]\n",
    "\n",
    "# 해당 list가 존재한다면, 파일 삭제\n",
    "if list_image_out_of_range:\n",
    "    for path in list_image_out_of_range:\n",
    "        os.remove(path)\n",
    "if list_label_out_of_range:\n",
    "    for path in list_label_out_of_range:\n",
    "        os.remove(path)\n",
    "\n",
    "IMAGE_SHAPE = (80, 120)\n",
    "data_root = home_dir+'/data/train/input'\n",
    "label_root = home_dir+'/data/train/label'\n",
    "\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "label_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "image_data = image_generator.flow_from_directory(str(data_root), class_mode=None, target_size=IMAGE_SHAPE, batch_size=32)\n",
    "label_data = label_generator.flow_from_directory(str(label_root), class_mode=None, target_size=IMAGE_SHAPE, batch_size=32)"
   ]
  },
  {
   "source": [
    "<br>\n",
    "\n",
    "### Dataset generator <br><br>\n",
    "\n",
    "모델 학습을 위한 데이터셋을 생성하는 함수를 작성 <br><br>\n",
    "\n",
    "image_generator 와 label generator 를 학습할 수 있는 입출력 형식으로 편집 <br>\n",
    "텐서플로우의 제너레이터(generator) 형식을 사용하고 있기 때문에 출력 형식도 맞추어 주기 <br><br>\n",
    "\n",
    "참고. <br>\n",
    "[제네레이터](https://tensorflow.blog/%ED%9A%8C%EC%98%A4%EB%A6%AC%EB%B0%94%EB%9E%8C%EC%9D%84-%ED%83%84-%ED%8C%8C%EC%9D%B4%EC%8D%AC/%EC%A0%9C%EB%84%88%EB%A0%88%EC%9D%B4%ED%84%B0/)\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습을 위한 데이터셋 생성하는 함수 작성\n",
    "\n",
    "def user_generation(train_generator, label_generator):\n",
    "    h, w = train_generator.target_size\n",
    "    for images, labels in zip(train_generator, label_generator):\n",
    "        images /= 255.\n",
    "        images = images[..., ::-1] # rgb to bgr\n",
    "\n",
    "        list_point_labels = []\n",
    "        for img, label in zip(images, labels):\n",
    "\n",
    "            eye_ls = np.where(label==1) # leftside\n",
    "            eye_rs = np.where(label==2) # rightside\n",
    "            eye_center = np.where(label==3)\n",
    "\n",
    "            lx, ly = [eye_ls[1].mean(), eye_ls[0].mean()]\n",
    "            rx, ry = [eye_rs[1].mean(), eye_rs[0].mean()]\n",
    "            cx, cy = [eye_center[1].mean(), eye_center[0].mean()]\n",
    "\n",
    "            if len(eye_ls[0])==0 or len(eye_ls[1])==0:\n",
    "                lx, ly = [0, 0]\n",
    "            if len(eye_rs[0])==0 or len(eye_rs[1])==0:\n",
    "                rx, ry = [w, h]\n",
    "            if len(eye_center[0])==0 or len(eye_center[1])==0:\n",
    "                cx, cy = [0, 0]\n",
    "\n",
    "            np_point_label = np.array([lx/w,ly/h,rx/w,ry/h,cx/w,cy/h], dtype=np.float32)\n",
    "\n",
    "            list_point_labels.append(np_point_label)\n",
    "        np_point_labels = np.array(list_point_labels)\n",
    "        yield (images, np_point_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(80, 120, 3) [0.        0.        1.        1.        0.5805595 0.4375   ]\n",
      "(80, 120, 3) [0.         0.         1.         1.         0.39166668 0.18701509]\n",
      "/home/ssac29/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: Mean of empty slice.\n",
      "  app.launch_new_instance()\n",
      "/home/ssac29/anaconda3/envs/aiffel/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/ssac29/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: Mean of empty slice.\n"
     ]
    }
   ],
   "source": [
    "# 생성한 user_generation 제네레이터 함수로 데이터 포인트를 뽑아 확인\n",
    "# 120x80의 정해진 크기로 이미지가 잘 출력되고 라벨 또한 0~1 갑ㅅ으로 정규화(normalize) 되어 있는 것을 확인\n",
    "\n",
    "user_train_generator = user_generation(image_data, label_data)\n",
    "for i in range(2):\n",
    "    dd = next(user_train_generator)\n",
    "    print (dd[0][0].shape, dd[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<br>\n",
    "\n",
    "## 모델 설계 : Keypoint 검출 딥러닝 모델 만들기 <br><br>\n",
    "\n",
    "\n",
    "\n",
    "<br>"
   ]
  }
 ]
}